{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import torch\n",
    "import math\n",
    "import gpytorch\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import xbatcher\n",
    "import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "baker_url = 's3://petrichor/geosmart/baker.zarr/'\n",
    "scg_url = 's3://petrichor/geosmart/scg.zarr/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "baker_ds = xr.open_dataset(baker_url, chunks='auto', engine='zarr', storage_options={\"anon\": True})\n",
    "scg_ds = xr.open_dataset(scg_url, chunks='auto', engine='zarr', storage_options={\"anon\": True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert time to numpy array\n",
    "#years_tens = torch.tensor(years.values)\n",
    "\n",
    "# Convert coordinates to tensors\n",
    "#x_tens = torch.tensor(baker_array.coords['x'].values)\n",
    "#y_tens = torch.tensor(baker_array.coords['y'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bgen = iter(xbatcher.BatchGenerator(baker_ds, {\"x\": 50, \"y\": 50, \"time\": 55}))\n",
    "chunk = next(bgen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(81921, 4)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data_og = chunk.band1.to_dataframe().dropna().reset_index()\n",
    "\n",
    "full_data_og.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data_og.to_csv(\"test_data_og.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>y</th>\n",
       "      <th>x</th>\n",
       "      <th>band1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>5.409449e+06</td>\n",
       "      <td>580947.438712</td>\n",
       "      <td>706.601624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>5.409449e+06</td>\n",
       "      <td>580948.438712</td>\n",
       "      <td>707.278198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>5.409449e+06</td>\n",
       "      <td>580949.438712</td>\n",
       "      <td>707.780396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>5.409449e+06</td>\n",
       "      <td>580950.438712</td>\n",
       "      <td>708.258789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>5.409449e+06</td>\n",
       "      <td>580951.438712</td>\n",
       "      <td>708.737122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81916</th>\n",
       "      <td>73.29589</td>\n",
       "      <td>5.409400e+06</td>\n",
       "      <td>580992.438712</td>\n",
       "      <td>719.607239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81917</th>\n",
       "      <td>73.29589</td>\n",
       "      <td>5.409400e+06</td>\n",
       "      <td>580993.438712</td>\n",
       "      <td>720.352295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81918</th>\n",
       "      <td>73.29589</td>\n",
       "      <td>5.409400e+06</td>\n",
       "      <td>580994.438712</td>\n",
       "      <td>721.066284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81919</th>\n",
       "      <td>73.29589</td>\n",
       "      <td>5.409400e+06</td>\n",
       "      <td>580995.438712</td>\n",
       "      <td>721.751221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81920</th>\n",
       "      <td>73.29589</td>\n",
       "      <td>5.409400e+06</td>\n",
       "      <td>580996.438712</td>\n",
       "      <td>722.386841</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>81921 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           time             y              x       band1\n",
       "0       0.00000  5.409449e+06  580947.438712  706.601624\n",
       "1       0.00000  5.409449e+06  580948.438712  707.278198\n",
       "2       0.00000  5.409449e+06  580949.438712  707.780396\n",
       "3       0.00000  5.409449e+06  580950.438712  708.258789\n",
       "4       0.00000  5.409449e+06  580951.438712  708.737122\n",
       "...         ...           ...            ...         ...\n",
       "81916  73.29589  5.409400e+06  580992.438712  719.607239\n",
       "81917  73.29589  5.409400e+06  580993.438712  720.352295\n",
       "81918  73.29589  5.409400e+06  580994.438712  721.066284\n",
       "81919  73.29589  5.409400e+06  580995.438712  721.751221\n",
       "81920  73.29589  5.409400e+06  580996.438712  722.386841\n",
       "\n",
       "[81921 rows x 4 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data = full_data_og\n",
    "\n",
    "# Convert timestamps to unix time, normalize by starting at 0 and also do it in years\n",
    "full_data['time'] = full_data['time'].astype('int64') / 1e9 / 60 / 60 / 24 / 365\n",
    "\n",
    "# Start at 0\n",
    "full_data['time'] = full_data['time'] - full_data['time'][0]\n",
    "\n",
    "full_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize x and y using StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "full_data['x'] = scaler.fit_transform(full_data['x'].values.reshape(-1, 1))\n",
    "full_data['y'] = scaler.fit_transform(full_data['y'].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partition full data into train and test sets. Do k fold cross validation on train set\n",
    "# Use the first 80% of the data as the train set\n",
    "def loadData(full_data, train_frac=0.8):\n",
    "    train_data = full_data.iloc[:int(train_frac * full_data.shape[0])]\n",
    "    test_data = full_data.iloc[int(train_frac * full_data.shape[0]):]\n",
    "\n",
    "    # Train time\n",
    "    train_time = torch.tensor(train_data['time'].values)\n",
    "    train_x = torch.tensor(train_data['x'].values)\n",
    "    train_y = torch.tensor(train_data['y'].values)\n",
    "    train_elev = torch.tensor(train_data['band1'].values)\n",
    "\n",
    "    # Test time\n",
    "    test_time = torch.tensor(test_data['time'].values)\n",
    "    test_x = torch.tensor(test_data['x'].values)\n",
    "    test_y = torch.tensor(test_data['y'].values)\n",
    "    test_elev = torch.tensor(test_data['band1'].values)\n",
    "\n",
    "    # Stack train_time, train_x, train_y\n",
    "    stacked_train = torch.stack([train_time, train_x, train_y], dim=1)\n",
    "\n",
    "    # Stack test_time, test_x, test_y\n",
    "    stacked_test = torch.stack([test_time, test_x, test_y], dim=1)\n",
    "\n",
    "    # Cast as double\n",
    "    stacked_train = stacked_train.double()\n",
    "    train_elev = train_elev.double()\n",
    "    stacked_test = stacked_test.double()\n",
    "    test_elev = test_elev.double()\n",
    "\n",
    "    return stacked_train, train_elev, stacked_test, test_elev\n",
    "\n",
    "stacked_train, train_elev, stacked_test, test_elev = loadData(full_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exact GP\n",
    "Let's first try a product RBF kernel in the form $\\mathbf{K} = K_t \\times K_x \\times K_y$, where $K_t$ is the kernel for the time dimension, and $K_x$ and $K_y$ are the kernels for the spatial dimensions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_train, train_elev, stacked_test, test_elev = loadData(full_data, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExactSpatioTemporalGP(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(ExactSpatioTemporalGP, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel(ard_num_dims=3))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "# initialize likelihood and model\n",
    "likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "model = ExactSpatioTemporalGP(stacked_train, train_elev, likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_iter = 1\n",
    "\n",
    "# Find optimal model hyperparameters\n",
    "model.train()\n",
    "likelihood.train()\n",
    "\n",
    "# Use the adam optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)  # Includes GaussianLikelihood parameters\n",
    "\n",
    "# \"Loss\" for GPs - the marginal log likelihood\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "for i in range(training_iter):\n",
    "    # Zero gradients from previous iteration\n",
    "    optimizer.zero_grad()\n",
    "    # Output from model\n",
    "    output = model(stacked_train)\n",
    "    # Calc loss and backprop gradients\n",
    "    loss = -mll(output, train_elev)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sparse GP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_train, train_elev, stacked_test, test_elev = loadData(full_data, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ekinokos2/mambaforge/envs/gtpy/lib/python3.11/site-packages/linear_operator/utils/cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-08 to the diagonal\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from gpytorch.means import ConstantMean\n",
    "from gpytorch.kernels import ScaleKernel, RBFKernel, InducingPointKernel\n",
    "from gpytorch.distributions import MultivariateNormal\n",
    "\n",
    "class SGPRegressionModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(SGPRegressionModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = ConstantMean()\n",
    "        self.base_covar_module = ScaleKernel(RBFKernel(ard_num_dims=3))\n",
    "        self.covar_module = InducingPointKernel(self.base_covar_module, inducing_points=train_x[:1000, :].clone(), likelihood=likelihood)\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return MultivariateNormal(mean_x, covar_x)\n",
    "    \n",
    "# initialize likelihood and model\n",
    "likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "model = SGPRegressionModel(stacked_train, train_elev, likelihood)\n",
    "\n",
    "training_iter = 1\n",
    "\n",
    "# Find optimal model hyperparameters\n",
    "model.train()\n",
    "likelihood.train()\n",
    "\n",
    "# Use the adam optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)  # Includes GaussianLikelihood parameters\n",
    "\n",
    "# \"Loss\" for GPs - the marginal log likelihood\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "for i in range(training_iter):\n",
    "    # Zero gradients from previous iteration\n",
    "    optimizer.zero_grad()\n",
    "    # Output from model\n",
    "    output = model(stacked_train)\n",
    "    # Calc loss and backprop gradients\n",
    "    loss = -mll(output, train_elev)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LargeFeatureExtractor(torch.nn.Sequential):\n",
    "    def __init__(self, input_dim):\n",
    "        super(LargeFeatureExtractor, self).__init__()\n",
    "        self.add_module('linear1', torch.nn.Linear(input_dim, 1000))\n",
    "        self.add_module('relu1', torch.nn.ReLU())\n",
    "        self.add_module('linear2', torch.nn.Linear(1000, 500))\n",
    "        self.add_module('relu2', torch.nn.ReLU())\n",
    "        self.add_module('linear3', torch.nn.Linear(500, 50))\n",
    "        self.add_module('relu3', torch.nn.ReLU())\n",
    "        self.add_module('linear4', torch.nn.Linear(50, 2))\n",
    "\n",
    "\n",
    "class GPRegressionModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(GPRegressionModel, self).__init__(train_x, train_y, likelihood)\n",
    "\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = gpytorch.kernels.GridInterpolationKernel(\n",
    "            gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel(ard_num_dims=3)),\n",
    "            grid_size=100, num_dims=3,\n",
    "        )\n",
    "\n",
    "        # Also add the deep net\n",
    "        self.feature_extractor = LargeFeatureExtractor(input_dim=train_x.size(-1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # We're first putting our data through a deep net (feature extractor)\n",
    "        # We're also scaling the features so that they're nice values\n",
    "        projected_x = self.feature_extractor(x)\n",
    "        projected_x = projected_x - projected_x.min(0)[0]\n",
    "        projected_x = 2 * (projected_x / projected_x.max(0)[0]) - 1\n",
    "\n",
    "        # The rest of this looks like what we've seen\n",
    "        mean_x = self.mean_module(projected_x)\n",
    "        covar_x = self.covar_module(projected_x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "\n",
    "likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "model = GPRegressionModel(stacked_train, train_elev, likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 must have the same dtype",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m<timed eval>:1\u001b[0m\n",
      "\u001b[1;32m/Users/ekinokos2/Library/CloudStorage/OneDrive-UW/spacetime-elevation/contributors/ekin/data_access.ipynb Cell 23\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ekinokos2/Library/CloudStorage/OneDrive-UW/spacetime-elevation/contributors/ekin/data_access.ipynb#X52sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(training_iterations):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ekinokos2/Library/CloudStorage/OneDrive-UW/spacetime-elevation/contributors/ekin/data_access.ipynb#X52sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/ekinokos2/Library/CloudStorage/OneDrive-UW/spacetime-elevation/contributors/ekin/data_access.ipynb#X52sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     output \u001b[39m=\u001b[39m model(stacked_train)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ekinokos2/Library/CloudStorage/OneDrive-UW/spacetime-elevation/contributors/ekin/data_access.ipynb#X52sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39m-\u001b[39mmll(output, train_elev)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ekinokos2/Library/CloudStorage/OneDrive-UW/spacetime-elevation/contributors/ekin/data_access.ipynb#X52sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/mambaforge/envs/gtpy/lib/python3.11/site-packages/gpytorch/models/exact_gp.py:268\u001b[0m, in \u001b[0;36mExactGP.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mall\u001b[39m(\n\u001b[1;32m    265\u001b[0m             torch\u001b[39m.\u001b[39mequal(train_input, \u001b[39minput\u001b[39m) \u001b[39mfor\u001b[39;00m train_input, \u001b[39minput\u001b[39m \u001b[39min\u001b[39;00m length_safe_zip(train_inputs, inputs)\n\u001b[1;32m    266\u001b[0m         ):\n\u001b[1;32m    267\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mYou must train on the training inputs!\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 268\u001b[0m     res \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(\u001b[39m*\u001b[39;49minputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    269\u001b[0m     \u001b[39mreturn\u001b[39;00m res\n\u001b[1;32m    271\u001b[0m \u001b[39m# Prior mode\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/gtpy/lib/python3.11/site-packages/gpytorch/module.py:31\u001b[0m, in \u001b[0;36mModule.__call__\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39minputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Union[Tensor, Distribution, LinearOperator]:\n\u001b[0;32m---> 31\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(\u001b[39m*\u001b[39;49minputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     32\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(outputs, \u001b[39mlist\u001b[39m):\n\u001b[1;32m     33\u001b[0m         \u001b[39mreturn\u001b[39;00m [_validate_module_outputs(output) \u001b[39mfor\u001b[39;00m output \u001b[39min\u001b[39;00m outputs]\n",
      "\u001b[1;32m/Users/ekinokos2/Library/CloudStorage/OneDrive-UW/spacetime-elevation/contributors/ekin/data_access.ipynb Cell 23\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ekinokos2/Library/CloudStorage/OneDrive-UW/spacetime-elevation/contributors/ekin/data_access.ipynb#X52sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ekinokos2/Library/CloudStorage/OneDrive-UW/spacetime-elevation/contributors/ekin/data_access.ipynb#X52sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m     \u001b[39m# We're first putting our data through a deep net (feature extractor)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ekinokos2/Library/CloudStorage/OneDrive-UW/spacetime-elevation/contributors/ekin/data_access.ipynb#X52sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     \u001b[39m# We're also scaling the features so that they're nice values\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/ekinokos2/Library/CloudStorage/OneDrive-UW/spacetime-elevation/contributors/ekin/data_access.ipynb#X52sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     projected_x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeature_extractor(x)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ekinokos2/Library/CloudStorage/OneDrive-UW/spacetime-elevation/contributors/ekin/data_access.ipynb#X52sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     projected_x \u001b[39m=\u001b[39m projected_x \u001b[39m-\u001b[39m projected_x\u001b[39m.\u001b[39mmin(\u001b[39m0\u001b[39m)[\u001b[39m0\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ekinokos2/Library/CloudStorage/OneDrive-UW/spacetime-elevation/contributors/ekin/data_access.ipynb#X52sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     projected_x \u001b[39m=\u001b[39m \u001b[39m2\u001b[39m \u001b[39m*\u001b[39m (projected_x \u001b[39m/\u001b[39m projected_x\u001b[39m.\u001b[39mmax(\u001b[39m0\u001b[39m)[\u001b[39m0\u001b[39m]) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/mambaforge/envs/gtpy/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/mambaforge/envs/gtpy/lib/python3.11/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/mambaforge/envs/gtpy/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/mambaforge/envs/gtpy/lib/python3.11/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 must have the same dtype"
     ]
    }
   ],
   "source": [
    "training_iterations = 10\n",
    "\n",
    "\n",
    "# Find optimal model hyperparameters\n",
    "model.train()\n",
    "likelihood.train()\n",
    "\n",
    "# Use the adam optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)  # Includes GaussianLikelihood parameters\n",
    "\n",
    "# \"Loss\" for GPs - the marginal log likelihood\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "\n",
    "def train():\n",
    "    #iterator = tqdm(range(training_iterations))\n",
    "    for i in range(training_iterations):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(stacked_train)\n",
    "        loss = -mll(output, train_elev)\n",
    "        loss.backward()\n",
    "        #iterator.set_postfix(loss=loss.item())\n",
    "        optimizer.step()\n",
    "\n",
    "%time train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VNNGP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_train, train_elev, stacked_test, test_elev = loadData(full_data, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpytorch.models import ApproximateGP\n",
    "from gpytorch.variational.nearest_neighbor_variational_strategy import NNVariationalStrategy\n",
    "\n",
    "\n",
    "class GPModel(ApproximateGP):\n",
    "    def __init__(self, inducing_points, likelihood, k=256, training_batch_size=256):\n",
    "\n",
    "        m, d = inducing_points.shape\n",
    "        self.m = m\n",
    "        self.k = k\n",
    "\n",
    "        variational_distribution = gpytorch.variational.MeanFieldVariationalDistribution(m)\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            inducing_points = inducing_points.cuda()\n",
    "\n",
    "        variational_strategy = NNVariationalStrategy(self, inducing_points, variational_distribution, k=k,\n",
    "                                                     training_batch_size=training_batch_size)\n",
    "        super(GPModel, self).__init__(variational_strategy)\n",
    "        self.mean_module = gpytorch.means.ZeroMean()\n",
    "        self.covar_module = gpytorch.kernels.MaternKernel(nu=2.5, ard_num_dims=d)\n",
    "\n",
    "        self.likelihood = likelihood\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "    def __call__(self, x, prior=False, **kwargs):\n",
    "        if x is not None:\n",
    "            if x.dim() == 1:\n",
    "                x = x.unsqueeze(-1)\n",
    "        return self.variational_strategy(x=x, prior=False, **kwargs)\n",
    "\n",
    "k = 256\n",
    "training_batch_size = 64\n",
    "\n",
    "likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "# Note: one should use full training set as inducing points!\n",
    "model = GPModel(inducing_points=stacked_train, likelihood=likelihood, k=k, training_batch_size=training_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "num_batches = model.variational_strategy._total_training_batches\n",
    "\n",
    "model.train()\n",
    "likelihood.train()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Our loss object. We're using the VariationalELBO\n",
    "mll = gpytorch.mlls.VariationalELBO(likelihood, model, num_data=train_elev.size(0))\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(x=None)\n",
    "    # Obtain the indices for mini-batch data\n",
    "    current_training_indices = model.variational_strategy.current_training_indices\n",
    "    # Obtain the y_batch using indices. It is important to keep the same order of train_x and train_y\n",
    "    y_batch = train_elev[...,current_training_indices]\n",
    "    if torch.cuda.is_available():\n",
    "        y_batch = y_batch.cuda()\n",
    "    loss = -mll(output, y_batch)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/ekinokos2/Library/CloudStorage/OneDrive-UW/spacetime-elevation/contributors/ekin/data_access.ipynb Cell 28\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ekinokos2/Library/CloudStorage/OneDrive-UW/spacetime-elevation/contributors/ekin/data_access.ipynb#Y114sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ekinokos2/Library/CloudStorage/OneDrive-UW/spacetime-elevation/contributors/ekin/data_access.ipynb#Y114sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     \u001b[39mfor\u001b[39;00m x_batch, y_batch \u001b[39min\u001b[39;00m test_loader:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/ekinokos2/Library/CloudStorage/OneDrive-UW/spacetime-elevation/contributors/ekin/data_access.ipynb#Y114sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m         preds \u001b[39m=\u001b[39m model(x_batch)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ekinokos2/Library/CloudStorage/OneDrive-UW/spacetime-elevation/contributors/ekin/data_access.ipynb#Y114sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m         means \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat([means, preds\u001b[39m.\u001b[39mmean\u001b[39m.\u001b[39mcpu()])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ekinokos2/Library/CloudStorage/OneDrive-UW/spacetime-elevation/contributors/ekin/data_access.ipynb#Y114sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m         diff \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mpow(preds\u001b[39m.\u001b[39mmean \u001b[39m-\u001b[39m y_batch, \u001b[39m2\u001b[39m)\n",
      "\u001b[1;32m/Users/ekinokos2/Library/CloudStorage/OneDrive-UW/spacetime-elevation/contributors/ekin/data_access.ipynb Cell 28\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ekinokos2/Library/CloudStorage/OneDrive-UW/spacetime-elevation/contributors/ekin/data_access.ipynb#Y114sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m     \u001b[39mif\u001b[39;00m x\u001b[39m.\u001b[39mdim() \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ekinokos2/Library/CloudStorage/OneDrive-UW/spacetime-elevation/contributors/ekin/data_access.ipynb#Y114sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m         x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39munsqueeze(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/ekinokos2/Library/CloudStorage/OneDrive-UW/spacetime-elevation/contributors/ekin/data_access.ipynb#Y114sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvariational_strategy(x\u001b[39m=\u001b[39;49mx, prior\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/mambaforge/envs/gtpy/lib/python3.11/site-packages/gpytorch/variational/nearest_neighbor_variational_strategy.py:150\u001b[0m, in \u001b[0;36mNNVariationalStrategy.__call__\u001b[0;34m(self, x, prior, **kwargs)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m     \u001b[39m# Ensure inducing_points and x are the same size\u001b[39;00m\n\u001b[1;32m    149\u001b[0m     inducing_points \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minducing_points\n\u001b[0;32m--> 150\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(x, inducing_points, inducing_values\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m, variational_inducing_covar\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/mambaforge/envs/gtpy/lib/python3.11/site-packages/gpytorch/variational/nearest_neighbor_variational_strategy.py:228\u001b[0m, in \u001b[0;36mNNVariationalStrategy.forward\u001b[0;34m(self, x, inducing_points, inducing_values, variational_inducing_covar, **kwargs)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[39massert\u001b[39;00m x\u001b[39m.\u001b[39mshape \u001b[39m==\u001b[39m (\u001b[39m*\u001b[39mx_batch_shape, x_bsz, \u001b[39m1\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mD)\n\u001b[1;32m    227\u001b[0m \u001b[39m# Compute forward mode in the standard way\u001b[39;00m\n\u001b[0;32m--> 228\u001b[0m dist \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mforward(x, inducing_points, inducing_values, variational_inducing_covar, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    229\u001b[0m predictive_mean \u001b[39m=\u001b[39m dist\u001b[39m.\u001b[39mmean  \u001b[39m# (*batch_shape, x_bsz, 1)\u001b[39;00m\n\u001b[1;32m    230\u001b[0m predictive_covar \u001b[39m=\u001b[39m dist\u001b[39m.\u001b[39mcovariance_matrix  \u001b[39m# (*batch_shape, x_bsz, 1, 1)\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/gtpy/lib/python3.11/site-packages/gpytorch/variational/unwhitened_variational_strategy.py:154\u001b[0m, in \u001b[0;36mUnwhitenedVariationalStrategy.forward\u001b[0;34m(self, x, inducing_points, inducing_values, variational_inducing_covar, **kwargs)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[39m# Compute Cholesky factorization of inducing covariance matrix\u001b[39;00m\n\u001b[1;32m    153\u001b[0m \u001b[39mif\u001b[39;00m settings\u001b[39m.\u001b[39mfast_computations\u001b[39m.\u001b[39mlog_prob\u001b[39m.\u001b[39moff() \u001b[39mor\u001b[39;00m (num_induc \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m settings\u001b[39m.\u001b[39mmax_cholesky_size\u001b[39m.\u001b[39mvalue()):\n\u001b[0;32m--> 154\u001b[0m     induc_induc_covar \u001b[39m=\u001b[39m CholLinearOperator(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cholesky_factor(induc_induc_covar))\n\u001b[1;32m    156\u001b[0m \u001b[39m# If we are making predictions and don't need variances, we can do things very quickly.\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining \u001b[39mand\u001b[39;00m settings\u001b[39m.\u001b[39mskip_posterior_variances\u001b[39m.\u001b[39mon():\n",
      "File \u001b[0;32m~/mambaforge/envs/gtpy/lib/python3.11/site-packages/gpytorch/variational/nearest_neighbor_variational_strategy.py:126\u001b[0m, in \u001b[0;36mNNVariationalStrategy._cholesky_factor\u001b[0;34m(self, induc_induc_covar)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_cholesky_factor\u001b[39m(\u001b[39mself\u001b[39m, induc_induc_covar: LinearOperator) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m TriangularLinearOperator:\n\u001b[1;32m    125\u001b[0m     \u001b[39m# Uncached version\u001b[39;00m\n\u001b[0;32m--> 126\u001b[0m     L \u001b[39m=\u001b[39m psd_safe_cholesky(to_dense(induc_induc_covar))\n\u001b[1;32m    127\u001b[0m     \u001b[39mreturn\u001b[39;00m TriangularLinearOperator(L)\n",
      "File \u001b[0;32m~/mambaforge/envs/gtpy/lib/python3.11/site-packages/linear_operator/utils/cholesky.py:65\u001b[0m, in \u001b[0;36mpsd_safe_cholesky\u001b[0;34m(A, upper, out, jitter, max_tries)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpsd_safe_cholesky\u001b[39m(A, upper\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, out\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, jitter\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, max_tries\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m     51\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Compute the Cholesky decomposition of A. If A is only p.s.d, add a small jitter to the diagonal.\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[39m        :attr:`A` (Tensor):\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[39m            Number of attempts (with successively increasing jitter) to make before raising an error.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 65\u001b[0m     L \u001b[39m=\u001b[39m _psd_safe_cholesky(A, out\u001b[39m=\u001b[39;49mout, jitter\u001b[39m=\u001b[39;49mjitter, max_tries\u001b[39m=\u001b[39;49mmax_tries)\n\u001b[1;32m     66\u001b[0m     \u001b[39mif\u001b[39;00m upper:\n\u001b[1;32m     67\u001b[0m         \u001b[39mif\u001b[39;00m out \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/mambaforge/envs/gtpy/lib/python3.11/site-packages/linear_operator/utils/cholesky.py:20\u001b[0m, in \u001b[0;36m_psd_safe_cholesky\u001b[0;34m(A, out, jitter, max_tries)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[39mif\u001b[39;00m out \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     18\u001b[0m     out \u001b[39m=\u001b[39m (out, torch\u001b[39m.\u001b[39mempty(A\u001b[39m.\u001b[39mshape[:\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m], dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mint32, device\u001b[39m=\u001b[39mout\u001b[39m.\u001b[39mdevice))\n\u001b[0;32m---> 20\u001b[0m L, info \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mlinalg\u001b[39m.\u001b[39;49mcholesky_ex(A, out\u001b[39m=\u001b[39;49mout)\n\u001b[1;32m     21\u001b[0m \u001b[39mif\u001b[39;00m settings\u001b[39m.\u001b[39mtrace_mode\u001b[39m.\u001b[39mon() \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m torch\u001b[39m.\u001b[39many(info):\n\u001b[1;32m     22\u001b[0m     \u001b[39mreturn\u001b[39;00m L\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "test_dataset = TensorDataset(stacked_test, test_elev)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "model.eval()\n",
    "likelihood.eval()\n",
    "means = torch.tensor([0.])\n",
    "test_mse = 0\n",
    "with torch.no_grad():\n",
    "    for x_batch, y_batch in test_loader:\n",
    "        preds = model(x_batch)\n",
    "        means = torch.cat([means, preds.mean.cpu()])\n",
    "\n",
    "        diff = torch.pow(preds.mean - y_batch, 2)\n",
    "        diff = diff.sum(dim=-1) / stacked_test.size(0) # sum over bsz and scaling\n",
    "        diff = diff.mean() # average over likelihood_nsamples\n",
    "        test_mse += diff\n",
    "means = means[1:]\n",
    "test_rmse = test_mse.sqrt().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([692.5970, 693.1428, 693.7226,  ..., 721.0663, 721.7512, 722.3868])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_rmse"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gtpy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
